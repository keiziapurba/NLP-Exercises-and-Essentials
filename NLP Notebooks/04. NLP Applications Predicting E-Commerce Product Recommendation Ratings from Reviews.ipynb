{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68e8706",
   "metadata": {},
   "source": [
    "# Predicting E-Commerce Product Recommendation Ratings from Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4fa93",
   "metadata": {},
   "source": [
    "This is a classic NLP problem dealing with data from an e-commerce store focusing on women's clothing. Each record in the dataset is a customer review which consists of the review title, text description and a rating (ranging from 1 - 5) for a product amongst other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535233f4",
   "metadata": {},
   "source": [
    "We convert this into a binary classification problem such that a customer recommends a product (label 1) is the rating is > 3 else they do not recommend the product (label 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3978ab",
   "metadata": {},
   "source": [
    "**Main Objective**: Leverage the review text attributes to predict the recommendation rating (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc106047",
   "metadata": {},
   "source": [
    "# Load up basic dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a820f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb0940",
   "metadata": {},
   "source": [
    "# Load and View the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b178e11",
   "metadata": {},
   "source": [
    "The data is available at https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews from where you can download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56c6d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                            \n",
       "1           1         1080   34                            \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/dipanjanS/feature_engineering_session_dhs18/master/ecommerce_product_ratings_prediction/Womens%20Clothing%20E-Commerce%20Reviews.csv', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de8238",
   "metadata": {},
   "source": [
    "# Basic Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84128e21",
   "metadata": {},
   "source": [
    "- Merge all review text attributes (title, text description) into one attribute\n",
    "- Convert the 5-star rating system into a binary recommendation rating of 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ae1066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some major design flaws I had such high hopes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flattering shirt This shirt is very flattering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  Absolutely wonderful - silky and sexy and comf...       1\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       1\n",
       "2  Some major design flaws I had such high hopes ...       0\n",
       "3  My favorite buy! I love, love, love this jumps...       1\n",
       "4  Flattering shirt This shirt is very flattering...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'] = (df['Title'].map(str) +' '+ df['Review Text']).apply(lambda row: row.strip())\n",
    "df['Rating'] = [1 if rating > 3 else 0 for rating in df['Rating']]\n",
    "df = df[['Review', 'Rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4eb74",
   "metadata": {},
   "source": [
    "## Remove all records with no review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320dcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22642 entries, 0 to 23485\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  22642 non-null  object\n",
      " 1   Rating  22642 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 530.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Review'] != '']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977d59c",
   "metadata": {},
   "source": [
    "## There is some imbalance in the data based on product ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf57f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17449\n",
       "0     5193\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04522f",
   "metadata": {},
   "source": [
    "# Build train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb0df0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16981, 1), (5661, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Review']], df['Rating'], random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a6bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 13059, 0: 3922}), Counter({1: 4390, 0: 1271}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05311d4",
   "metadata": {},
   "source": [
    "# Experiment 1: Basic NLP Count based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd92d68",
   "metadata": {},
   "source": [
    "A number of basic text based features can also be created which sometimes are helpful for improving text classification models. Some examples are:\n",
    "\n",
    "- **Word Count**: total number of words in the documents\n",
    "- **Character Count**: total number of characters in the documents\n",
    "- **Average Word Density**: average length of the words used in the documents\n",
    "- **Puncutation Count**: total number of punctuation marks in the documents\n",
    "- **Upper Case Count**: total number of upper count words in the documents\n",
    "- **Title Word Count**: total number of proper case (title) words in the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265e3ac",
   "metadata": {},
   "source": [
    "Source: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf1bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "X_train['char_count'] = X_train['Review'].apply(len)\n",
    "X_train['word_count'] = X_train['Review'].apply(lambda x: len(x.split()))\n",
    "X_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\n",
    "X_train['punctuation_count'] = X_train['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_train['title_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_train['upper_case_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "\n",
    "X_test['char_count'] = X_test['Review'].apply(len)\n",
    "X_test['word_count'] = X_test['Review'].apply(lambda x: len(x.split()))\n",
    "X_test['word_density'] = X_test['char_count'] / (X_test['word_count']+1)\n",
    "X_test['punctuation_count'] = X_test['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_test['title_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_test['upper_case_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781a89a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fl...</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally v...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter i...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  char_count  \\\n",
       "12896  Soooo soft! This is a delightfully soft and fl...         268   \n",
       "13183  Had my eye on this, but dind't get I finally v...         399   \n",
       "1496   I wanted to like this... I wanted to like this...         525   \n",
       "5205   Beautiful blouse Bought this for my daughter i...         203   \n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\...         295   \n",
       "\n",
       "       word_count  word_density  punctuation_count  title_word_count  \\\n",
       "12896          52      5.056604                  8                 2   \n",
       "13183          84      4.694118                 20                 2   \n",
       "1496          104      5.000000                 19                 2   \n",
       "5205           35      5.638889                 10                 2   \n",
       "13366          51      5.673077                 22                 2   \n",
       "\n",
       "       upper_case_word_count  \n",
       "12896                      0  \n",
       "13183                      1  \n",
       "1496                       2  \n",
       "5205                       0  \n",
       "13366                      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c7b2e",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b0eb8",
   "metadata": {},
   "source": [
    "A logistic regression model is easy to train, interpret and works well on a wide variety of NLP problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e580f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63c322",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics - Quick Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba694e",
   "metadata": {},
   "source": [
    "Just accuracy is never enough in datasets with a rare class problem.\n",
    "\n",
    "- **Precision**: The positive predictive power of a model. Out of all the predictions made by a model for a class, how many are actually correct\n",
    "- **Recall**: The coverage or hit-rate of a model. Out of all the test data samples belonging to a class, how many was the model able to predict (hit or cover) correctly.\n",
    "- **F1-score**: The harmonic mean of the precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60fbfb0",
   "metadata": {},
   "source": [
    "Do check out ROC Curve, AUC Score and PR Curve also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23c1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1271\n",
      "           1       0.78      1.00      0.87      4390\n",
      "\n",
      "    accuracy                           0.78      5661\n",
      "   macro avg       0.39      0.50      0.44      5661\n",
      "weighted avg       0.60      0.78      0.68      5661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1\n",
       "0  0  1271\n",
       "1  0  4390"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e3452",
   "metadata": {},
   "source": [
    "Looks like our model was not able to predict a single product having a bad (no recommendation) rating, i.e. **Class 0**.\n",
    "\n",
    "This is as good as someone predicting a 1 or good for every product review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057ae9d",
   "metadata": {},
   "source": [
    "# Leveraging Text Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62897a2b",
   "metadata": {},
   "source": [
    "Reviews are pretty subjective, opinionated and people often express stong emotions, feelings. This makes it a classic case where the text documents here are a good candidate for extracting sentiment as a feature.\n",
    "\n",
    "The general expectation is that highly rated and recommended products (**label 1**) should have a **positive** sentiment and products which are not recommended (**label 0**) should have a negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d211a5",
   "metadata": {},
   "source": [
    "TextBlob is an excellent open-source library for performing NLP tasks with ease, including sentiment analysis. It also an a sentiment lexicon (in the form of an XML file) which it leverages to give both polarity and subjectivity scores.\n",
    "\n",
    "- The polarity score is a float within the range [-1.0, 1.0].\n",
    "- The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e4552",
   "metadata": {},
   "source": [
    "Source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6039a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::anaconda==2022.05=py39_0\n",
      "  - defaults/osx-64::gensim==4.1.2=py39he9d5cce_0\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/keiziapurba/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-2022.05  |           py39_0           7 KB\n",
      "    anaconda-custom            |           py39_1           4 KB\n",
      "    ca-certificates-2022.6.15  |       h033912b_0         149 KB  conda-forge\n",
      "    certifi-2022.6.15          |   py39h6e9494a_0         155 KB  conda-forge\n",
      "    conda-4.13.0               |   py39h6e9494a_1         986 KB  conda-forge\n",
      "    openssl-1.1.1q             |       hfe4f2af_0         1.9 MB  conda-forge\n",
      "    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n",
      "    smart_open-6.0.0           |     pyhd8ed1ab_0          43 KB  conda-forge\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/osx-64::_anaconda_depends-2022.05-py39_0\n",
      "  python_abi         conda-forge/osx-64::python_abi-3.9-2_cp39\n",
      "  smart_open         conda-forge/noarch::smart_open-6.0.0-pyhd8ed1ab_0\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.3.29-~ --> conda-forge::ca-certificates-2022.6.15-h033912b_0\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py39hecd~ --> conda-forge::certifi-2022.6.15-py39h6e9494a_0\n",
      "  conda              pkgs/main::conda-4.13.0-py39hecd8cb5_0 --> conda-forge::conda-4.13.0-py39h6e9494a_1\n",
      "  openssl              pkgs/main::openssl-1.1.1n-hca72f7f_0 --> conda-forge::openssl-1.1.1q-hfe4f2af_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                                   2022.05-py39_0 --> custom-py39_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.13.0         | 986 KB    | ##################################### | 100% \n",
      "openssl-1.1.1q       | 1.9 MB    | ##################################### | 100% \n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "_anaconda_depends-20 | 7 KB      | ##################################### | 100% \n",
      "python_abi-3.9       | 4 KB      | ##################################### | 100% \n",
      "anaconda-custom      | 4 KB      | ##################################### | 100% \n",
      "ca-certificates-2022 | 149 KB    | ##################################### | 100% \n",
      "smart_open-6.0.0     | 43 KB     | ##################################### | 100% \n",
      "certifi-2022.6.15    | 155 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d89503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "\n",
    "textblob.TextBlob('This is an AMAZING pair of Jeans!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a18c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.95, subjectivity=0.85)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('I really hated this UGLY T-shirt!!').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b95a9",
   "metadata": {},
   "source": [
    "Looks like this should help us get features which can distinguish between good and bad products. Let's try it out on our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e20658",
   "metadata": {},
   "source": [
    "# Experiment 2: Features from Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc480245",
   "metadata": {},
   "source": [
    "Remember this is unsupervised, lexicon-based sentiment analysis where we don't have any pre-labeled data saying which review migth have a positive or negative sentiment. We use the lexicon to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c16dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_snt_obj = X_train['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b889becd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fl...</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally v...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter i...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  char_count  \\\n",
       "12896  Soooo soft! This is a delightfully soft and fl...         268   \n",
       "13183  Had my eye on this, but dind't get I finally v...         399   \n",
       "1496   I wanted to like this... I wanted to like this...         525   \n",
       "5205   Beautiful blouse Bought this for my daughter i...         203   \n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\...         295   \n",
       "\n",
       "       word_count  word_density  punctuation_count  title_word_count  \\\n",
       "12896          52      5.056604                  8                 2   \n",
       "13183          84      4.694118                 20                 2   \n",
       "1496          104      5.000000                 19                 2   \n",
       "5205           35      5.638889                 10                 2   \n",
       "13366          51      5.673077                 22                 2   \n",
       "\n",
       "       upper_case_word_count  Polarity  Subjectivity  \n",
       "12896                      0  0.170455      0.490909  \n",
       "13183                      1  0.101944      0.719537  \n",
       "1496                       2  0.186538      0.458761  \n",
       "5205                       0  0.625000      0.825000  \n",
       "13366                      0  0.329613      0.510268  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43970c80",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c51630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.27      0.38      1271\n",
      "           1       0.82      0.96      0.89      4390\n",
      "\n",
      "    accuracy                           0.81      5661\n",
      "   macro avg       0.75      0.62      0.64      5661\n",
      "weighted avg       0.79      0.81      0.77      5661\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>4236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  339   932\n",
       "1  154  4236"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train, )\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af9cf2",
   "metadata": {},
   "source": [
    "Looks like we are now able to predict **27%** of the total number of bad or negative rated products now! Precision is quite good at **69%**.\n",
    "\n",
    "**F1-Score** for bad reviews is now **40%** and good reviews is **89%**.\n",
    "\n",
    "This brings our overall **F1-Score** to **77%** which is quite good.\n",
    "\n",
    "Can we still improve on our model since the recall of bad reviews is still pretty low?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae02245",
   "metadata": {},
   "source": [
    "# Text Pre-processing and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca86748",
   "metadata": {},
   "source": [
    "We want to extract some specific features based on standard NLP feature engineering models like the classic Bag of Words model. For this we need to clean and pre-process our text data. We will build a simple text pre-processor here since the main intent is to look at feature engineering strategies.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "- Text Lowercasing\n",
    "- Removal of contractions\n",
    "- Removing unnecessary characters, numbers and symbols\n",
    "- Stemming\n",
    "- Stopword removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e9f1b",
   "metadata": {},
   "source": [
    "Source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d65429f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (0.1.72)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: anyascii in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: pyahocorasick in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: textsearch in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (from textsearch) (1.4.4)\n",
      "Requirement already satisfied: anyascii in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (from textsearch) (0.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages (4.64.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/keiziapurba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/keiziapurba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch\n",
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5beaa288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I did not like this t-shirt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "contractions.fix('I didn\\'t like this t-shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ded19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    document = contractions.fix(document)\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59206183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fl...</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>soooo soft thi delight soft fluffi sweater mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally v...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "      <td>eye thi but dind get final visit store petit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>want like thi want like thi top badli badli fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter i...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>beauti blous bought thi daughter law birthday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "      <td>boxi larg boxi unflatt larg curvi pound thi to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  char_count  \\\n",
       "12896  Soooo soft! This is a delightfully soft and fl...         268   \n",
       "13183  Had my eye on this, but dind't get I finally v...         399   \n",
       "1496   I wanted to like this... I wanted to like this...         525   \n",
       "5205   Beautiful blouse Bought this for my daughter i...         203   \n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\...         295   \n",
       "\n",
       "       word_count  word_density  punctuation_count  title_word_count  \\\n",
       "12896          52      5.056604                  8                 2   \n",
       "13183          84      4.694118                 20                 2   \n",
       "1496          104      5.000000                 19                 2   \n",
       "5205           35      5.638889                 10                 2   \n",
       "13366          51      5.673077                 22                 2   \n",
       "\n",
       "       upper_case_word_count  Polarity  Subjectivity  \\\n",
       "12896                      0  0.170455      0.490909   \n",
       "13183                      1  0.101944      0.719537   \n",
       "1496                       2  0.186538      0.458761   \n",
       "5205                       0  0.625000      0.825000   \n",
       "13366                      0  0.329613      0.510268   \n",
       "\n",
       "                                            Clean Review  \n",
       "12896  soooo soft thi delight soft fluffi sweater mig...  \n",
       "13183  eye thi but dind get final visit store petit t...  \n",
       "1496   want like thi want like thi top badli badli fa...  \n",
       "5205   beauti blous bought thi daughter law birthday ...  \n",
       "13366  boxi larg boxi unflatt larg curvi pound thi to...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Clean Review'] = stp(X_train['Review'].values)\n",
    "X_test['Clean Review'] = stp(X_test['Review'].values)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e9bae",
   "metadata": {},
   "source": [
    "## Extracting out the structured features from previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28c59f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         268          52      5.056604                  8                 2   \n",
       "1         399          84      4.694118                 20                 2   \n",
       "2         525         104      5.000000                 19                 2   \n",
       "3         203          35      5.638889                 10                 2   \n",
       "4         295          51      5.673077                 22                 2   \n",
       "\n",
       "   upper_case_word_count  Polarity  Subjectivity  \n",
       "0                      0  0.170455      0.490909  \n",
       "1                      1  0.101944      0.719537  \n",
       "2                      2  0.186538      0.458761  \n",
       "3                      0  0.625000      0.825000  \n",
       "4                      0  0.329613      0.510268  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_metadata = X_train.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "X_test_metadata = X_test.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc32489",
   "metadata": {},
   "source": [
    "# Experiment 3: Adding Bag of Words based Features - 1-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a585b5f",
   "metadata": {},
   "source": [
    "This is perhaps the most simple vector space representational model for unstructured text. A vector space model is simply a mathematical model to represent unstructured text (or any other data) as numeric vectors, such that each dimension of the vector is a specific feature\\attribute.\n",
    "\n",
    "The bag of words model represents each text document as a numeric vector where each dimension is a specific word from the corpus and the value could be its frequency in the document, occurrence (denoted by 1 or 0) or even weighted values.\n",
    "\n",
    "The models name is such because each document is represented literally as a bag of its own words, disregarding word orders, sequences and grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ee738",
   "metadata": {},
   "source": [
    "Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27f02196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/keiziapurba/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandidon</th>\n",
       "      <th>aaaaannnnnnd</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahmaz</th>\n",
       "      <th>aaah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>abck</th>\n",
       "      <th>...</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  8545 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaaandidon  aaaaannnnnnd  aaaah  aaaahmaz  aaah  ab  abbey  abbi  \\\n",
       "0   0            0             0      0         0     0   0      0     0   \n",
       "1   0            0             0      0         0     0   0      0     0   \n",
       "2   0            0             0      0         0     0   0      0     0   \n",
       "3   0            0             0      0         0     0   0      0     0   \n",
       "4   0            0             0      0         0     0   0      0     0   \n",
       "\n",
       "   abck  ...  zing  zip  zipper  zipperi  zippi  zone  zooland  zoom  zowi  \\\n",
       "0     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "1     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "2     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "3     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "4     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "\n",
       "   zuma  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 8545 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc78a895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandidon</th>\n",
       "      <th>...</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  8553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         268          52      5.056604                  8                 2   \n",
       "1         399          84      4.694118                 20                 2   \n",
       "2         525         104      5.000000                 19                 2   \n",
       "3         203          35      5.638889                 10                 2   \n",
       "4         295          51      5.673077                 22                 2   \n",
       "\n",
       "   upper_case_word_count  Polarity  Subjectivity  aa  aaaaandidon  ...  zing  \\\n",
       "0                      0  0.170455      0.490909   0            0  ...     0   \n",
       "1                      1  0.101944      0.719537   0            0  ...     0   \n",
       "2                      2  0.186538      0.458761   0            0  ...     0   \n",
       "3                      0  0.625000      0.825000   0            0  ...     0   \n",
       "4                      0  0.329613      0.510268   0            0  ...     0   \n",
       "\n",
       "   zip  zipper  zipperi  zippi  zone  zooland  zoom  zowi  zuma  \n",
       "0    0       0        0      0     0        0     0     0     0  \n",
       "1    0       0        0      0     0        0     0     0     0  \n",
       "2    0       0        0      0     0        0     0     0     0  \n",
       "3    0       0        0      0     0        0     0     0     0  \n",
       "4    0       0        0      0     0        0     0     0     0  \n",
       "\n",
       "[5 rows x 8553 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63ebc3",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6590b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73      1271\n",
      "           1       0.92      0.94      0.93      4390\n",
      "\n",
      "    accuracy                           0.88      5661\n",
      "   macro avg       0.84      0.82      0.83      5661\n",
      "weighted avg       0.88      0.88      0.88      5661\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>897</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  897   374\n",
       "1  285  4105"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a22c3",
   "metadata": {},
   "source": [
    "We are now able to predict **70%** of the total number of bad or negative rated products now! Precision is quite good at **76%**\n",
    "\n",
    "**F1-Score** for bad reviews is now **73%** and good reviews is **92%**\n",
    "\n",
    "This brings our overall **F1-Score** to **88%** which is quite good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
